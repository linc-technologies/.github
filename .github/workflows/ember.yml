name: "Ember"

on:
  pull_request:
  workflow_dispatch:
  workflow_call:
    # TODO: Deprecate these as we move to helm
    inputs:
      DEPLOYMENT:
        description: "The name of the Kubernetes deployment to deploy to, ex: app-app-deployment"
        type: string
        required: true
      CONTAINER:
        description: "The name of the container within the Kubernetes deployment to patch, ex: app-app-deployment -c app-app"
        type: string
        required: true

env:
  CONTAINER_REGISTRY: linced.azurecr.io/linc-ed

jobs:
  build:
    name: "Build"
    runs-on: ubuntu-latest
    outputs:
      build_num: ${{ steps.tag.outputs.build_num }}
      image_tag_build: ${{ steps.tag.outputs.image_tag_build }}
      image_tag_branch: ${{ steps.tag.outputs.image_tag_branch }}
    steps:

      - name: "Checkout"
        uses: actions/checkout@v2

      - name: "Git SSH"
        if: ${{ github.actor != 'dependabot[bot]' }}
        uses: linc-technologies/.github/.github/actions/git_ssh@master
        with:
          key: ${{ secrets.VCS_SSH_KEY }}

      - name: "Setup Node 10.21"
        uses: actions/setup-node@v3
        with:
          node-version: 10.21
          cache: 'npm'
          cache-dependency-path: linced-*/package-lock.json

      - name: "Login to ACR"
        uses: docker/login-action@v2
        with:
          registry: linced.azurecr.io
          username: ${{ secrets.AZURE_ACR_LINCED_USERNAME }}
          password: ${{ secrets.AZURE_ACR_LINCED_PASSWORD }}

      - name: "Install Dependencies (npm ci)"
        run: |
          cd linced-*
          npm ci

      - name: "Set Branch Environment Variables"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        uses: iamtheyammer/branch-env-vars@v1.1.3
        with:
          bevOverwrite: true
          bevSetEmptyVars: true
          APP_FQDN: |
            testing:${{secrets.DEVELOPMENT_APP_FQDN}}
            development:${{secrets.DEVELOPMENT_APP_FQDN}}
            staging:${{secrets.STAGING_APP_FQDN}}
            production:${{secrets.PRODUCTION_APP_FQDN}}

      - name: "Lint JavaScript"
        if: contains(fromJson('["linced-app"]'), github.event.repository.name)
        run: |
          cd linced-*
          npm run lint:js

      - name: "Lint Handlebar Templates"
        if: contains(fromJson('["linced-app"]'), github.event.repository.name)
        run: |
          cd linced-*
          npm run lint:hbs

      # TODO: Get working tests one day
#      - name: "Run Ember Tests"
#        run: |
#          cd linced-*
#          npm run test

      - name: "Ember CLI Install"
        run: |
          npm install -g ember-cli@3.16
          which ember || echo "Could not find 'ember'"
          which ember

      - name: "Ember Build"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        env:
          BUILD: ${{ github.run_number }}
        run: |
          cd linced-*

          # Create build version
          export BUILD_NUM=$(( $BUILD + 10000 ))
          export APP_VERSION=$( echo "${{ github.ref_name }}.${BUILD_NUM}" | tr '/' '-')
          echo "Linced Build Version: ${APP_VERSION}"

          # Install
          ember build --environment ${{ github.ref_name }}

          # Post install stuff and things.
          cd dist/assets
          mkdir update
          cp linced-*.* update/ || true
          cp vendor-*.* update/ || true

      - name: "Create Sentry Release"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        env:
          SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}
          SENTRY_ORG: ${{ secrets.SENTRY_ORG }}
          SENTRY_PROJECT: ${{ github.event.repository.name }}
          # SENTRY_URL: https://sentry.io/
          BUILD: ${{ github.run_number }}
        run: |
          cd linced-*
          
          # Download sentry cli
          curl -sL https://sentry.io/get-cli/ | SENTRY_CLI_VERSION=2.0.4 bash

          # Setup ENV vars for release
          export BUILD_NUM=$(( $BUILD + 10000 ))
          export APP_VERSION="$( echo "${{ github.ref_name }}.${BUILD_NUM}" | tr '/' '-')"
          export APP_RELEASE="${{github.event.repository.name}}@${APP_VERSION}"
          
          sentry-cli releases new $APP_RELEASE
          sentry-cli releases files $APP_RELEASE upload-sourcemaps ./dist
          sentry-cli releases finalize $APP_RELEASE
          
          # Cleanup
          rm -rf $(find dist/ -type f -name "*.map")

        # NOTE: We copy the previous assets in to smooth clients' transition from the old build to the new.
        # Else sometimes a client can use cached HTML from a previous build which tries to fetch the previous assets.
        # This partially makes up for a lack of CDN...Still not stellar
      - name: "Add Previous Assets"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        continue-on-error: true
        run: |
          IMAGE_TAG="$CONTAINER_REGISTRY/${{ github.event.repository.name }}:${{ github.ref_name }}"
          docker pull $IMAGE_TAG
          docker run -d --rm --name "previous_assets" --entrypoint "" $IMAGE_TAG sleep infinity
          docker cp previous_assets:/usr/share/nginx/html/assets/update ./previous_assets
          docker rm --force previous_assets
          ls -la ./**/dist/assets || true
          cp -u ./previous_assets/linced-*.* ./**/dist/assets/ || true
          cp -u ./previous_assets/vendor-*.* ./**/dist/assets/ || true
          ls -la ./**/dist/assets || true

      - name: "Set Ownership"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        run: sudo chown -Rv 101:101 ./linced-*/dist/*

      - name: "Set up Docker Buildx"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        uses: docker/setup-buildx-action@v2

      - name: "Export build tag"
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        id: tag
        env:
          BUILD: ${{ github.run_number }}
        run: |
          echo "::set-output name=build_num::$(($BUILD+10000))"
          echo "::set-output name=image_tag_build::${{env.CONTAINER_REGISTRY}}/${{ github.event.repository.name }}:$(($BUILD+10000))"
          echo "::set-output name=image_tag_branch::${{env.CONTAINER_REGISTRY}}/${{ github.event.repository.name }}:${{github.ref_name}}"

#      - name: "Build and export to Docker"
#        uses: docker/build-push-action@v3
#        if: ${{ !contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name) }}
#        id: push_build_tag
#        with:
#          context: .
#          push: true
#          tags: ${{ steps.tag.outputs.image_tag_build }}
#          file: Dockerfile.drone

      - name: "Build and export to Docker (Environmental Tags)"
        uses: docker/build-push-action@v3
        if: contains(fromJson('["testing", "development", "staging", "production"]'), github.ref_name)
        id: push_build_and_env_tag
        with:
          context: .
          push: true
          tags: |
            ${{ steps.tag.outputs.image_tag_build }}
            ${{ steps.tag.outputs.image_tag_branch }}
          file: Dockerfile.drone

      - name: "Slack Notify"
        if: success() || failure()
        uses: linc-technologies/.github/.github/actions/slack_notify@master
        continue-on-error: true
        with:
          event: build
          success: ${{ !contains(steps.*.outcome, 'failure') }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}


  deploy:
    name: "Deploy"
    if: contains(fromJson('["development", "staging", "production"]'), github.ref_name)
    runs-on: ubuntu-latest
    needs: [build]
    steps:

      # In order to retrieve deployment config
      - name: "Checkout"
        uses: actions/checkout@v2

      - name: "Install Kubectl"
        uses: azure/setup-kubectl@v2.0
        with:
          version: 'v1.22.6'

      # If we're deploying from a non-production branch, configure Kubectl with Dev cluster secrets
      - name: "Kubernetes Auth (Dev AU East)"
        if: ${{ github.ref  != 'refs/heads/production' }}
        run: |
          kubectl config set-credentials default --token=${{ secrets.DEVELOPMENT_AU_EAST_AKS_TOKEN }}
          # If cert provided...
          # kubectl config set-cluster default --server=${{ secrets.DEVELOPMENT_AU_EAST_AKS_SERVER }} --certificate-authority=ca.crt
          # If cert not provided
          kubectl config set-cluster default --server=${{ secrets.DEVELOPMENT_AU_EAST_AKS_SERVER }} --insecure-skip-tls-verify=true
          kubectl config set-context default --cluster=default --user=default
          kubectl config use-context default

      # If we're deploying from a production branch, configure Kubectl with Prod cluster secrets
      - name: "Kubernetes Auth (Prod AU East)"
        if: ${{ github.ref == 'refs/heads/production' }}
        run: |
          kubectl config set-credentials default --token=${{ secrets.PRODUCTION_AU_EAST_AKS_TOKEN }}
          # If cert provided...
          # kubectl config set-cluster default --server=${{ secrets.PRODUCTION_AU_EAST_AKS_SERVER }} --certificate-authority=ca.crt
          # If cert not provided
          kubectl config set-cluster default --server=${{ secrets.PRODUCTION_AU_EAST_AKS_SERVER }} --insecure-skip-tls-verify=true
          kubectl config set-context default --cluster=default --user=default
          kubectl config use-context default

      - name: "Kubectl Version"
        run: kubectl version

      - name: "Release Name"
        id: release_name
        run: |
          NAME=$(echo "${{ github.event.repository.name }}" | sed -e 's/linced-//g')
          echo "::set-output name=release_name::${NAME}"

      - name: "Helm Deploy"
        id: helm
        uses: linc-technologies/.github/.github/actions/deploy_helm@master
        # TODO: Adjust this filter for Staging, and Production when ready to cutover.
        # TODO: Only testing the admin app currently
        if: ${{ github.ref_name == 'development' && github.event.repository.name == 'linced-admin' }}
        with:
          chart: "app"
          release: ${{ steps.release_name.outputs.release_name }}
          namespace: ${{ github.ref_name }}
          tag: ${{ needs.build.outputs.build_num }}
          oci_user: ${{ secrets.AZURE_ACR_LINCED_USERNAME }}
          oci_pass: ${{ secrets.AZURE_ACR_LINCED_PASSWORD }}

      # Deploy to other environments if we did not deploy with Helm (Staging, Production) via k8s Deployment patch
      # TODO: Remove once fully cutover
      # Deploy specific container revision based on workflow inputs
      - name: "Kubernetes Deploy"
        if: steps.helm.conclusion == 'skipped'
        env:
          CONTAINER: ${{ inputs.CONTAINER }}
          DEPLOYMENT: ${{ inputs.DEPLOYMENT }}
          NAMESPACE: ${{ github.ref_name }}
          IMAGE: ${{ needs.build.outputs.image_tag_build }}
        run: |
          echo "Updating $CONTAINER in $DEPLOYMENT to $IMAGE in the $NAMESPACE namespace."
          kubectl set image deployment/$DEPLOYMENT  $CONTAINER=$IMAGE --record=true --namespace=${NAMESPACE}

      - name: "Slack Notify"
        if: success() || failure()
        uses: linc-technologies/.github/.github/actions/slack_notify@master
        continue-on-error: true
        with:
          event: deploy
          success: ${{ !contains(steps.*.outcome, 'failure') }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
